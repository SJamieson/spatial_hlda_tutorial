{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Replicating \"Unsupervised discovery of visual object class hierarchies\" (Sivic et al., 2018)\n",
    "#### By: Stewart Jamieson\n",
    "Paper citation: Sivic, J., Russell, B. C., Zisserman, A., Freeman, W. T., & Efros, A. A. (2008). Unsupervised discovery of visual object class hierarchies. 2008 IEEE Conference on Computer Vision and Pattern Recognition, 1â€“8. https://doi.org/10.1109/CVPR.2008.4587622\n",
    "\n",
    "Make sure to run the following cell so that the dependencies are loaded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q matplotlib pillow networkx pygraphviz hlda\n",
    "import os\n",
    "try:\n",
    "    os.chdir(os.getcwd() + '/notebooks')\n",
    "except:\n",
    "    pass\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from hierarchy_plotting import *\n",
    "from IPython.display import display\n",
    "from hlda.sampler import HierarchicalLDA\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "## The Generative Model\n",
    "First, let's try to recreate figure #3(a) from the title reference (Sivic et al., 2008). The figure is the following:\n",
    "\n",
    "![Sivic et al. 2008 Figure #3](figures/sivic_fig3.png)\n",
    "\n",
    "So, the first thing we need to be able to do is generate our training set data, which will be composed of 'word' observations. To do so, we use the generative model for hLDA presented in the paper:\n",
    "\n",
    "![Sivic et al. 2008 hLDA Graphical Model](figures/hlda_graphical_model.png)\n",
    "\n",
    "To generate the visual words $\\{w_i\\}_{i=1}^N$, we need to first generate:\n",
    "1. A set distributions of topics over words: $\\{\\beta_i\\}_{i=1}^K$\n",
    "1. A tree structure $T$ with depth $L$ containing $K$ topics\n",
    "2. A path $\\mathbf{c}$ of length $L$ through the tree for each image (document)\n",
    "1. A topic distribution $\\theta$ over the topics in the path for every image (document)\n",
    "\n",
    "In Figure #3 of the Sivic paper, the $\\beta$ distributions and $T$ are fixed, and we will replicate the same structure. Let's begin by representing the $\\beta$ distributions, which show the word distribution of each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_band(x=None, y=None, save=None):\n",
    "    img = Image.new('L', (5, 5), color=255)\n",
    "    pix = img.load()\n",
    "    if x is not None:\n",
    "        for i in range(img.height):\n",
    "            pix[x, i] = 0\n",
    "    if y is not None:\n",
    "        for i in range(img.width):\n",
    "            pix[i, y] = 0\n",
    "    if save:\n",
    "        plt.imsave(save + '.png', np.array(img), cmap='gray', vmin=0, vmax=255)\n",
    "    return np.array(img, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "The `create_band()` function allows us to create an image of a single band, which will represent a topic. For example, to create a vertical band at x=1, we do the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f70256a2198>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAACL9JREFUeJzt3c9rnAUex/HPZ9OKggseOgdpysaDyBZhLQ5F6K14qD/Qq4KehF5WqCCIHv0HxIuXosUFRRH0IMVFCraI4KoTrWI3CkW6WBQyRUR7UaqfPWQORZvOk87z5Jn58n5BIJM8TD6EvPPMj5BxEgGo6S99DwDQHQIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoLAdXVzprl27srKy0sVVt251dbXvCVty55139j0Bc+DcuXO6cOGCpx3XSeArKysajUZdXHXr7Knfo7myKN9XdGs4HDY6jpvoQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4U1ihw24dsf237rO2nux4FoB1TA7e9JOkFSfdI2ivpYdt7ux4GYHZNzuD7JZ1N8k2SXyW9LunBbmcBaEOTwHdL+vayy+cnHwMw55oEfqX/SvinFxW3fdj2yPZoPB7PvgzAzJoEfl7SnssuL0v67o8HJTmaZJhkOBgM2toHYAZNAv9E0q22b7F9naSHJL3d7SwAbZj6f9GTXLL9uKR3JS1JOpbkTOfLAMys0QsfJHlH0jsdbwHQMv6SDSiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKGxq4LaP2V63/eV2DALQniZn8JclHep4B4AOTA08yfuSftiGLQBaxn1woLDWArd92PbI9mg8Hrd1tQBm0FrgSY4mGSYZDgaDtq4WwAy4iQ4U1uRpstckfSjpNtvnbT/W/SwAbdgx7YAkD2/HEADt4yY6UBiBA4UROFAYgQOFEThQGIEDhRE4UBiBA4UROFAYgQOFEThQGIEDhRE4UBiBA4UROFAYgQOFEThQGIEDhRE4UBiBA4UROFAYgQOFEThQGIEDhRE4UBiBA4UROFAYgQOFEThQGIEDhRE4UBiBA4UROFAYgQOFTQ3c9h7bJ22v2T5j+8h2DAMwux0Njrkk6ckkn9r+q6RV2yeS/LfjbQBmNPUMnuT7JJ9O3v9Z0pqk3V0PAzC7Ld0Ht70iaZ+kj7oYA6BdjQO3faOkNyU9keSnK3z+sO2R7dF4PG5zI4Br1Chw2zu1EferSd660jFJjiYZJhkOBoM2NwK4Rk0eRbeklyStJXmu+0kA2tLkDH5A0qOSDto+PXm7t+NdAFow9WmyJB9I8jZsAdAy/pINKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwobGrgtq+3/bHtz22fsf3sdgwDMLsdDY75RdLBJBdt75T0ge1/J/lPx9sAzGhq4Eki6eLk4s7JW7ocBaAdje6D216yfVrSuqQTST7qdhaANjQKPMlvSe6QtCxpv+3b/3iM7cO2R7ZH4/G47Z0ArsGWHkVP8qOkU5IOXeFzR5MMkwwHg0FL8wDMosmj6APbN03ev0HS3ZK+6noYgNk1eRT9Zkn/sr2kjV8IbyQ53u0sAG1o8ij6F5L2bcMWAC3jL9mAwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCisceC2l2x/Zvt4l4MAtGcrZ/Ajkta6GgKgfY0Ct70s6T5JL3Y7B0Cbmp7Bn5f0lKTfO9wCoGVTA7d9v6T1JKtTjjtse2R7NB6PWxsI4No1OYMfkPSA7XOSXpd00PYrfzwoydEkwyTDwWDQ8kwA12Jq4EmeSbKcZEXSQ5LeS/JI58sAzIznwYHCdmzl4CSnJJ3qZAmA1nEGBwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCnOS9q/UHkv6X8tXu0vShZavs0uLtHeRtkqLtberrX9LMvW/m3YSeBdsj5IM+97R1CLtXaSt0mLt7XsrN9GBwggcKGyRAj/a94AtWqS9i7RVWqy9vW5dmPvgALZukc7gALZoIQK3fcj217bP2n667z1XY/uY7XXbX/a9ZRrbe2yftL1m+4ztI31v2ozt621/bPvzydZn+97UhO0l25/ZPt7H15/7wG0vSXpB0j2S9kp62Pbefldd1cuSDvU9oqFLkp5M8ndJd0n65xx/b3+RdDDJPyTdIemQ7bt63tTEEUlrfX3xuQ9c0n5JZ5N8k+RXbbzC6YM9b9pUkvcl/dD3jiaSfJ/k08n7P2vjB3F3v6uuLBsuTi7unLzN9QNItpcl3Sfpxb42LELguyV9e9nl85rTH8JFZntF0j5JH/W7ZHOTm7unJa1LOpFkbrdOPC/pKUm/9zVgEQL3FT4217+5F43tGyW9KemJJD/1vWczSX5LcoekZUn7bd/e96bN2L5f0nqS1T53LELg5yXtuezysqTvetpSju2d2oj71SRv9b2niSQ/auNVbuf5sY4Dkh6wfU4bdysP2n5lu0csQuCfSLrV9i22r5P0kKS3e95Ugm1LeknSWpLn+t5zNbYHtm+avH+DpLslfdXvqs0leSbJcpIVbfzMvpfkke3eMfeBJ7kk6XFJ72rjQaA3kpzpd9XmbL8m6UNJt9k+b/uxvjddxQFJj2rj7HJ68nZv36M2cbOkk7a/0MYv/RNJennqaZHwl2xAYXN/Bgdw7QgcKIzAgcIIHCiMwIHCCBwojMCBwggcKOz/hQzbBmVNxXkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic = {}\n",
    "topic[1] = create_band(x=1, save='figures/z1')\n",
    "plt.imshow(Image.fromarray(topic[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's enumerate the bands used in the hierarchy from Figure #3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "topic[2] = create_band(y=1, save='figures/z2')\n",
    "topic[3] = create_band(x=3, save='figures/z3')\n",
    "topic[4] = create_band(y=0, save='figures/z4')\n",
    "topic[5] = create_band(x=4, save='figures/z5') \n",
    "topic[6] = create_band(y=2, save='figures/z6')\n",
    "topic[7] = create_band(x=0, save='figures/z7')\n",
    "topic[8] = create_band(y=3, save='figures/z8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "To visualize them, it would help to have the tree structure. For that, let's recreate the tree from Figure #3:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, name, children):\n",
    "        self.name = name\n",
    "        self.children = children\n",
    "        self.weight = 0\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        if item == 0:\n",
    "            return self.name\n",
    "        elif item == 1:\n",
    "            return self.children\n",
    "        elif item == 2:\n",
    "            return self.weight\n",
    "\n",
    "tree =\\\n",
    "[Node(1, [\n",
    "    Node(2, [\n",
    "        Node(4, None), Node(5, None)\n",
    "    ]),\n",
    "    Node(3, [\n",
    "        Node(6, None), Node(7, None), Node(8, None)\n",
    "    ])\n",
    "])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "The next step is to plot the tree, which we can do using the `networkx` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stewart/anaconda3/envs/stats/lib/python3.6/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_graph_from_tree(G, level):\n",
    "    for node in level:\n",
    "        G.add_node(node[0], image=f'figures/z{node[0]}.png')\n",
    "        if node[1] is not None:\n",
    "            build_graph_from_tree(G, node[1])\n",
    "            for child in node[1]:\n",
    "                G.add_edge(node[0], child[0])\n",
    "\n",
    "G = nx.DiGraph()\n",
    "build_graph_from_tree(G, tree)\n",
    "tree_fig : plt.Figure = plt.figure()\n",
    "plot_image_hierarchy(tree_fig, G)\n",
    "tree_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's go ahead and sample an image from each path of the tree. As in the paper, we are going to use topic proportions sampled from a Dirichlet prior with $\\alpha = [50, 30, 10]$. This means that the words will be drawn more often from the root node, less often from the middle node and even less often from the leaf node of the path. Also, since each $\\alpha_i \\gg 1$, each image will contain a mix of words from all topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta = [0.6322987  0.27853168 0.08916963]\n"
     ]
    }
   ],
   "source": [
    "alpha = np.array([50, 30, 10])\n",
    "theta = np.random.dirichlet(alpha)\n",
    "print('theta =', theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now all that's left to do is to enumerate all the paths through the tree and generate the word distribution of each document using its topic distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def all_paths(root):\n",
    "    paths = []\n",
    "    base_path = [root[0]]\n",
    "    if root[1] is None:\n",
    "        return [base_path]\n",
    "    \n",
    "    for child in root[1]:\n",
    "        child_paths = all_paths(child)\n",
    "        paths.extend([(base_path + child_path) for child_path in child_paths])\n",
    "    return paths\n",
    "\n",
    "unique_paths = all_paths(tree[0])\n",
    "word_dists = []\n",
    "\n",
    "def get_word_dist(topics, path, alpha):\n",
    "    theta = np.random.dirichlet(alpha)\n",
    "    weighted_components = [(topic[z] * theta[i]) for i, z in enumerate(path)]\n",
    "    return np.sum(weighted_components, axis=0)\n",
    "\n",
    "# display(tree_fig)\n",
    "fig = plt.figure()\n",
    "for i, path in enumerate(unique_paths):\n",
    "    fig.add_subplot(1, len(unique_paths), i+1)\n",
    "    word_dists.append(get_word_dist(topic, path, alpha))\n",
    "    plt.imshow(Image.fromarray(word_dists[-1]))\n",
    "    plt.title(f'{path}')\n",
    "    plt.gca().set_xticks([])\n",
    "    plt.gca().set_yticks([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "We can tell that our our word distributions are good because they already resemble the sample images from Figure 3. Now all that's left to do is to sample documents from them. To do so, we will treat the pixel intensities as the weights of a categorical distribution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_words = 250\n",
    "\n",
    "def sample_document(word_dist):\n",
    "    flat_word_dist = 255 - word_dist.reshape(-1)\n",
    "    doc_words = np.random.multinomial(n_words, flat_word_dist / np.sum(flat_word_dist))\n",
    "    doc_image = 255 - (doc_words.reshape(word_dist.shape).astype(np.uint8) * (255 / np.max(doc_words)))\n",
    "    return doc_image, doc_words\n",
    "\n",
    "display(tree_fig)\n",
    "fig = plt.figure()\n",
    "for i, path in enumerate(unique_paths):\n",
    "    fig.add_subplot(1, len(unique_paths), i+1)\n",
    "    \n",
    "    sample_doc = sample_document(word_dists[i])[0]\n",
    "    plt.imshow(Image.fromarray(sample_doc))\n",
    "    plt.title(f'{path}')\n",
    "    plt.gca().set_xticks([])\n",
    "    plt.gca().set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "So, we can tell that our generative process works since the figure closely matches 3(a) from the paper:\n",
    "\n",
    "![Sivic et al. 2008 Figure #3](figures/sivic_fig3_small.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Inference on the Model\n",
    "\n",
    "Now that we can sample documents from arbitrary word distributions, let's generate a larger corpus of documents to use for inference. To do so, we'll need to randomly sample paths from the tree.\n",
    "\n",
    "For now, we will assume that at each branch the decision is made uniformly over the available choices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_documents = 100\n",
    "\n",
    "def sample_path(node):\n",
    "    path = [node[0]]\n",
    "    if node[1] is not None:\n",
    "        child = np.random.choice(len(node[1]))\n",
    "        path.extend(sample_path(node[1][child]))\n",
    "    return path\n",
    "\n",
    "random_paths = [sample_path(tree[0]) for _ in range(n_documents)]\n",
    "word_dists = [get_word_dist(topic, path, alpha) for path in random_paths]\n",
    "corpus = [sample_document(word_dist) for word_dist in word_dists]\n",
    "\n",
    "fig = plt.figure()\n",
    "num_plots = 6\n",
    "for i in range(num_plots):\n",
    "    fig.add_subplot(1, num_plots, i+1)\n",
    "    plt.imshow(Image.fromarray(corpus[i][0]))\n",
    "    plt.title(f'{random_paths[i]}')\n",
    "    plt.gca().set_xticks([])\n",
    "    plt.gca().set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that we have a corpus, we perform inference using Gibbs sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HierarchicalLDA sampling\n",
      ".................................................. 50\n",
      "topic 0 (level=0, total_words=7770, documents=100): 1, 6, 21, 16, 11, \n",
      "    topic 3 (level=1, total_words=5415, documents=68): 11, 21, 16, 1, 6, \n",
      "        topic 6 (level=2, total_words=2288, documents=23): 18, 23, 3, 13, 19, \n",
      "        topic 13 (level=2, total_words=250, documents=2): 18, 13, 3, 23, 8, \n",
      "        topic 14 (level=2, total_words=2073, documents=22): 9, 6, 7, 5, 19, \n",
      "        topic 15 (level=2, total_words=1888, documents=21): 6, 7, 9, 5, 0, \n",
      "    topic 7 (level=1, total_words=1234, documents=13): 13, 11, 21, 18, 3, \n",
      "        topic 11 (level=2, total_words=999, documents=13): 23, 16, 18, 20, 0, \n",
      "    topic 9 (level=1, total_words=1646, documents=19): 11, 21, 6, 1, 13, \n",
      "        topic 12 (level=2, total_words=1437, documents=19): 13, 3, 18, 23, 8, \n",
      ".................................................. 100\n",
      "topic 0 (level=0, total_words=8024, documents=100): 6, 21, 1, 16, 11, \n",
      "    topic 3 (level=1, total_words=5512, documents=68): 11, 1, 16, 21, 6, \n",
      "        topic 6 (level=2, total_words=2261, documents=23): 18, 23, 3, 13, 19, \n",
      "        topic 13 (level=2, total_words=252, documents=2): 18, 13, 3, 23, 8, \n",
      "        topic 14 (level=2, total_words=1937, documents=22): 9, 7, 5, 6, 19, \n",
      "        topic 15 (level=2, total_words=1844, documents=21): 7, 6, 9, 5, 0, \n",
      "    topic 7 (level=1, total_words=1000, documents=13): 23, 13, 3, 11, 8, \n",
      "        topic 11 (level=2, total_words=943, documents=13): 16, 18, 21, 20, 5, \n",
      "    topic 9 (level=1, total_words=1644, documents=19): 11, 1, 21, 6, 13, \n",
      "        topic 12 (level=2, total_words=1583, documents=19): 13, 3, 23, 18, 16, \n",
      ".................................................. 150\n",
      "topic 0 (level=0, total_words=8282, documents=100): 6, 1, 21, 16, 11, \n",
      "    topic 3 (level=1, total_words=5110, documents=68): 11, 16, 21, 1, 6, \n",
      "        topic 6 (level=2, total_words=2244, documents=23): 18, 23, 3, 13, 19, \n",
      "        topic 13 (level=2, total_words=260, documents=2): 18, 13, 3, 23, 8, \n",
      "        topic 14 (level=2, total_words=2068, documents=22): 9, 6, 7, 5, 19, \n",
      "        topic 15 (level=2, total_words=1669, documents=21): 7, 9, 5, 6, 0, \n",
      "    topic 7 (level=1, total_words=1196, documents=13): 11, 3, 13, 18, 8, \n",
      "        topic 11 (level=2, total_words=987, documents=13): 16, 6, 21, 0, 23, \n",
      "    topic 9 (level=1, total_words=1642, documents=19): 11, 21, 13, 1, 6, \n",
      "        topic 12 (level=2, total_words=1542, documents=19): 3, 23, 18, 16, 13, \n",
      ".................................................. 200\n",
      "topic 0 (level=0, total_words=7942, documents=100): 6, 1, 21, 16, 11, \n",
      "    topic 3 (level=1, total_words=5383, documents=68): 11, 16, 21, 1, 6, \n",
      "        topic 6 (level=2, total_words=2248, documents=23): 18, 23, 3, 13, 19, \n",
      "        topic 13 (level=2, total_words=258, documents=2): 18, 13, 3, 23, 8, \n",
      "        topic 14 (level=2, total_words=2078, documents=22): 9, 7, 5, 6, 8, \n",
      "        topic 15 (level=2, total_words=1867, documents=21): 7, 9, 6, 5, 0, \n",
      "    topic 7 (level=1, total_words=1106, documents=13): 13, 11, 3, 18, 8, \n",
      "        topic 11 (level=2, total_words=1024, documents=13): 16, 6, 21, 23, 18, \n",
      "    topic 9 (level=1, total_words=1519, documents=19): 11, 21, 1, 6, 12, \n",
      "        topic 12 (level=2, total_words=1575, documents=19): 13, 3, 23, 18, 8, \n",
      ".................................................. 250\n",
      "topic 0 (level=0, total_words=7740, documents=100): 1, 6, 21, 16, 11, \n",
      "    topic 3 (level=1, total_words=5217, documents=68): 11, 16, 21, 6, 1, \n",
      "        topic 6 (level=2, total_words=2264, documents=23): 18, 23, 3, 13, 8, \n",
      "        topic 13 (level=2, total_words=260, documents=2): 18, 13, 3, 23, 8, \n",
      "        topic 14 (level=2, total_words=2209, documents=22): 9, 6, 7, 5, 8, \n",
      "        topic 15 (level=2, total_words=1955, documents=21): 6, 7, 9, 5, 0, \n",
      "    topic 7 (level=1, total_words=1061, documents=13): 13, 3, 8, 18, 11, \n",
      "        topic 11 (level=2, total_words=1105, documents=13): 16, 23, 21, 6, 18, \n",
      "    topic 9 (level=1, total_words=1636, documents=19): 11, 21, 6, 1, 12, \n",
      "        topic 12 (level=2, total_words=1553, documents=19): 13, 3, 18, 16, 8, \n",
      ".................................................. 300\n",
      "topic 0 (level=0, total_words=8202, documents=100): 6, 21, 1, 16, 11, \n",
      "    topic 3 (level=1, total_words=5200, documents=68): 11, 16, 1, 21, 8, \n",
      "        topic 6 (level=2, total_words=2171, documents=23): 18, 23, 3, 13, 19, \n",
      "        topic 13 (level=2, total_words=246, documents=2): 18, 13, 3, 23, 8, \n",
      "        topic 14 (level=2, total_words=2033, documents=22): 9, 7, 5, 6, 19, \n",
      "        topic 15 (level=2, total_words=1880, documents=21): 6, 7, 9, 5, 0, \n",
      "    topic 7 (level=1, total_words=1124, documents=13): 13, 3, 8, 18, 23, \n",
      "        topic 11 (level=2, total_words=1093, documents=13): 16, 21, 1, 6, 20, \n",
      "    topic 9 (level=1, total_words=1565, documents=19): 11, 13, 21, 1, 12, \n",
      "        topic 12 (level=2, total_words=1486, documents=19): 3, 18, 8, 13, 16, \n",
      ".................................................. 350\n",
      "topic 0 (level=0, total_words=8083, documents=100): 6, 1, 21, 16, 11, \n",
      "    topic 3 (level=1, total_words=5552, documents=68): 11, 16, 1, 21, 6, \n",
      "        topic 6 (level=2, total_words=2067, documents=23): 18, 23, 3, 13, 19, \n",
      "        topic 13 (level=2, total_words=255, documents=2): 18, 13, 3, 23, 8, \n",
      "        topic 14 (level=2, total_words=1983, documents=22): 9, 7, 5, 6, 19, \n",
      "        topic 15 (level=2, total_words=1817, documents=21): 7, 9, 6, 5, 0, \n",
      "    topic 7 (level=1, total_words=1180, documents=13): 23, 13, 18, 3, 8, \n",
      "        topic 11 (level=2, total_words=1002, documents=13): 6, 16, 11, 1, 20, \n",
      "    topic 9 (level=1, total_words=1606, documents=19): 11, 13, 1, 21, 6, \n",
      "        topic 12 (level=2, total_words=1455, documents=19): 3, 18, 23, 8, 13, \n",
      ".................................................. 400\n",
      "topic 0 (level=0, total_words=8474, documents=100): 6, 21, 11, 16, 1, \n",
      "    topic 3 (level=1, total_words=5134, documents=68): 8, 16, 1, 11, 21, \n",
      "        topic 6 (level=2, total_words=2071, documents=23): 18, 23, 3, 13, 19, \n",
      "        topic 13 (level=2, total_words=281, documents=2): 18, 13, 3, 23, 8, \n",
      "        topic 14 (level=2, total_words=2072, documents=22): 9, 6, 7, 5, 19, \n",
      "        topic 15 (level=2, total_words=1916, documents=21): 6, 7, 9, 5, 1, \n",
      "    topic 7 (level=1, total_words=1119, documents=13): 23, 8, 13, 3, 18, \n",
      "        topic 11 (level=2, total_words=946, documents=13): 16, 11, 1, 6, 20, \n",
      "    topic 9 (level=1, total_words=1458, documents=19): 11, 13, 1, 21, 12, \n",
      "        topic 12 (level=2, total_words=1529, documents=19): 8, 3, 23, 18, 13, \n",
      ".................................................. 450\n",
      "topic 0 (level=0, total_words=8096, documents=100): 11, 6, 1, 16, 21, \n",
      "    topic 3 (level=1, total_words=5432, documents=68): 21, 8, 16, 1, 6, \n",
      "        topic 6 (level=2, total_words=2085, documents=23): 18, 23, 3, 13, 19, \n",
      "        topic 13 (level=2, total_words=230, documents=2): 18, 13, 3, 23, 10, \n",
      "        topic 14 (level=2, total_words=2066, documents=22): 9, 6, 7, 5, 19, \n",
      "        topic 15 (level=2, total_words=1955, documents=21): 6, 7, 9, 5, 1, \n",
      "    topic 7 (level=1, total_words=1104, documents=13): 23, 18, 8, 13, 3, \n",
      "        topic 11 (level=2, total_words=1031, documents=13): 16, 6, 21, 1, 20, \n",
      "    topic 9 (level=1, total_words=1591, documents=19): 11, 13, 21, 1, 10, \n",
      "        topic 12 (level=2, total_words=1410, documents=19): 23, 8, 18, 3, 16, \n",
      ".................................................. 500\n",
      "topic 0 (level=0, total_words=7855, documents=100): 6, 1, 11, 16, 21, \n",
      "    topic 3 (level=1, total_words=5645, documents=68): 21, 8, 16, 11, 1, \n",
      "        topic 6 (level=2, total_words=2077, documents=23): 18, 23, 3, 13, 19, \n",
      "        topic 13 (level=2, total_words=245, documents=2): 18, 13, 3, 23, 10, \n",
      "        topic 14 (level=2, total_words=2000, documents=22): 9, 7, 5, 6, 19, \n",
      "        topic 15 (level=2, total_words=1906, documents=21): 6, 7, 9, 5, 1, \n",
      "    topic 7 (level=1, total_words=1196, documents=13): 23, 18, 8, 13, 3, \n",
      "        topic 11 (level=2, total_words=971, documents=13): 21, 16, 6, 11, 20, \n",
      "    topic 9 (level=1, total_words=1478, documents=19): 11, 21, 1, 13, 12, \n",
      "        topic 12 (level=2, total_words=1627, documents=19): 8, 23, 3, 18, 13, \n"
     ]
    }
   ],
   "source": [
    "word_corpus = []\n",
    "for document in corpus:\n",
    "    words = []\n",
    "    word_counts = document[1]\n",
    "    for i in range(word_counts.size):\n",
    "        words += [i] * word_counts[i]\n",
    "    word_corpus.append(words)\n",
    "vocab = list(range(word_counts.size))\n",
    "\n",
    "n_samples = 500       # no of iterations for the sampler\n",
    "alpha = 10.0          # smoothing over level ddddistributions\n",
    "gamma = 1.0           # CRP smoothing parameter; number of imaginary customers at next, as yet unused table\n",
    "eta = 0.1             # smoothing over topic-word distributions\n",
    "num_levels = 3        # the number of levels in the tree\n",
    "display_topics = 50   # the number of iterations between printing a brief summary of the topics so far\n",
    "n_words = 5           # the number of most probable words to print for each topic after model estimation\n",
    "with_weights = False  # whether to print the words with the weights\n",
    "\n",
    "hlda = HierarchicalLDA(word_corpus, vocab, alpha=alpha, gamma=gamma, eta=eta, num_levels=num_levels)\n",
    "hlda.estimate(n_samples, display_topics=display_topics, n_words=n_words, with_weights=with_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
